# Ratelimit服务流量限制

计算机程序可依据瓶颈分为磁盘 IO、CPU 计算、网络带宽瓶颈型，分布式场景下有时候也会因为外部系统而导致自身瓶颈，

对于 IO/Network 瓶颈类的程序，其表现是网卡 / 磁盘 IO 会先于 CPU 打满，这种情况即使优化 CPU 的使用也不能提高吞吐量，

只能提高磁盘的读写速度，增加内存大小，提升网卡的带宽来提升整体性能；

而 CPU 瓶颈类的程序，则是在存储和网卡未打满之前 CPU 占用率先到达 100%，CPU 忙于各种计算任务，IO 设备相对则较闲。

<strong>不管 Web 服务瓶颈在哪里，最终要做的事情都是一样的，那就是流量限制。</strong>

## 常见的流量限制手段

流量限制的手段有很多，最常见的：漏桶、令牌桶两种：

* 漏桶是假设有一个一直装满水的桶，每过固定的一段时间即向外漏一滴水，

  如果请求接到了这滴水，那么就可以继续服务请求，如果没有接到，那么就需要等待下一滴水。

* 令牌桶则是指匀速向桶中添加令牌，服务请求时需要从桶中获取令牌，令牌的数目可以按照需要消耗的资源进行相应的调整，

  如果没有令牌，可以选择等待，或者放弃。

这两种方法看起来很像，不过还是有区别的。漏桶流出的速率固定，而令牌桶只要在桶中有令牌，那就可以拿，

也就是说令牌桶是允许一定程度的并发，比如同一个时刻，有 100 个请求，桶中有 100 个令牌，那么全部请求都会放过去，

<strong>令牌桶在桶中没有令牌的情况下会退化为漏桶模型。</strong>

实际应用中令牌桶应用较为广泛，开源界流行的限流器大多数都是基于令牌桶思想的，并且在此基础上进行扩充，

比如 `github.com/juju/ratelimit` 提供了集中不同特色的令牌桶填充方式：

```go
func NewBucket(fillInterval time.Duration, capacity int64) *Bucket
```

`fillInterval` 指每过多长时间向桶里放一个令牌，`capacity` 是桶的容量，超过桶容量的部分会被直接丢弃，桶初始是满的。

```go
func NewBucketWithQuantum(fillInterval time.Duration, capacity, quantum int64) *Bucket
```

和普通的 `NewBucket()` 的区别是，每次向桶中放令牌时，是放 `quantum` 个令牌，而不是一个令牌。

```go
func NewBucketWithRate(rate float64, capacity int64) *Bucket
```

这个就有点特殊了，会按照提供的比例，每秒钟填充令牌数。例如 `capacity` 是 100，而 `rate` 是 0.1，那么每秒会填充 10 个令牌。

从桶中获取令牌也提供了几个 API：

```go
func (tb *Bucket) Take(count int64) time.Duration {}
func (tb *Bucket) TakeAvailable(count int64) int64 {}
func (tb *Bucket) TakeMaxDuration(count int64, maxWait time.Duration) (
    time.Duration, bool,
) {}
func (tb *Bucket) Wait(count int64) {}
func (tb *Bucket) WaitMaxDuration(count int64, maxWait time.Duration) bool {}
```

名称和功能都比较直观，这里就不再赘述了。相比于开源界更为有名的 Google 的 Java 工具库 Guava 中提供的 ratelimiter，

这个库不支持令牌桶预热，且无法修改初始的令牌容量，所以可能个别极端情况下的需求无法满足，

但在明白令牌桶的基本原理之后，如果没办法满足需求，相信你也可以很快对其进行修改并支持自己的业务场景。

## 原理

从功能上来看，令牌桶模型就是对全局计数的加减法操作过程，但使用计数需要加读写锁，

如果对 Go 语言已经比较熟悉的话，很容易想到可以用 buffered channel 来完成简单的加令牌取令牌操作：

```go
package main

import (
    "fmt"
    "time"
)

func main() {
    var fillInterval = time.Millisecond * 10
    var capacity = 100
    var tokenBucket = make(chan struct{}, capacity)

    fillToken := func() {
        ticker := time.NewTicker(fillInterval)
        for {
            select {
            case <-ticker.C:
                select {
                // 每过一段时间向 tokenBucket 中添加 token，如果 bucket 已经满了，那么直接放弃
                case tokenBucket <- struct{}{}:
                default:
                }
                fmt.Println("current token cnt:", len(tokenBucket), time.Now())
            }
        }
    }

    go fillToken()
    time.Sleep(time.Hour)
}
```

上面的令牌桶的取令牌操作实现起来也比较简单，简化问题，这里只取一个令牌：

```go
func TakeAvailable(block bool) bool{
    var takenResult bool
    if block {
        select {
        case <-tokenBucket:
            takenResult = true
        }
    } else {
        select {
        case <-tokenBucket:
            takenResult = true
        default:
            takenResult = false
        }
    }

    return takenResult
}
```

上述只是简单地介绍原理，但是实际上还会有很多优化项以及细节需要注意。

## 服务瓶颈和QoS

前面说了很多 CPU 瓶颈、IO 瓶颈之类的概念，这种性能瓶颈从大多数公司都有的监控系统中可以比较快速地定位出来，

如果一个系统遇到了性能问题，那监控图的反应一般都是最快的。

<strong>虽然性能指标很重要，但对用户提供服务时还应考虑服务整体的 QoS。QoS 全称是 Quality of Service，顾名思义是服务质量。</strong>

QoS 包含有可用性、吞吐量、时延、时延变化和丢失等指标。一般来讲我们可以通过优化系统，来提高 Web 服务的 CPU 利用率，

从而提高整个系统的吞吐量。但吞吐量提高的同时，用户体验是有可能变差的。用户角度比较敏感的除了可用性之外，还有时延。

虽然系统吞吐量高，但半天刷不开页面，想必会造成大量的用户流失。所以在大公司的 Web 服务性能指标中，除了平均响应时延之外，

还会把响应时间的 95 分位，99 分位也拿出来作为性能标准，平均响应在提高 CPU 利用率没受到太大影响时，

可能 95 分位、99 分位的响应时间大幅度攀升了，那么这时候就要考虑提高这些 CPU 利用率所付出的代价是否值得了。

在线系统的机器一般都会保持 CPU 有一定的余裕。