# 面向并发的内存模型

常见的并行编程有多种模型，主要有多线程、消息传递等，从理论上看，多线程和基于消息是等价的。

由于主流的操作系统提供了系统级的多线程支持，因此多线程编程模型逐步被吸纳到编程语言特性中，

而对于基于消息的并发编程模型支持则相比较少，Erlang 语言是基于消息传递并发编程模型的代表者，

它的并发体之间不共享内存，Go 语言是基于消息并发模型的集大成者，但 Goroutine 之间是共享内存的。

## Goroutine和系统线程

在 Go 语言的实现中 goroutine 和系统线程不是等价的，是一种轻量级的线程，称为协程，由 go 关键字启动，

尽管两者的区别实际上只是一个量的区别，但正是这个量变引发了 Go 语言并发编程质的的飞跃。

首先，每个系统级线程都会有一个固定大小的栈（一般默认可能是 2MB），这个栈主要用来保存函数递归调用时参数和局部变量。

固定栈的大小导致两个问题：

* 对于很多只需要很小的栈空间的线程来说是一个巨大的浪费
* 对于少数需要巨大栈空间的线程来说又面临栈溢出的风险

解决这两个问题的方案是：

* 降低固定栈的大小，提高空间利用率
* 增大栈的大小以允许更深的函数递归调用

但是这两者是没法同时兼得的，而 Goroutine 以一个很小的栈启动（可能是 2KB 或 4KB），当遇到栈空间不足时，

Goroutine 会根据需要动态地伸缩栈的大小（主流实现中栈的最大值可达到 1GB），因此可以轻易启动成千上万个协程。

运行时包含自己的调度器，可以使得 n 个操作系统线程上多工调度 m 个 goroutine，即 GMP，

其调度方式和内核是相似的，但是这个调度器只关注 Go 程序调度，发生在用户态，避免了上下文切换带来的消耗，

运行时有一个 `runtime.GOMAXPROCS` 变量，用于控制当前运行正常非阻塞 Goroutine 的系统线程数目。

## 原子操作

所谓原子操作是指并发编程中：最小的且不可并行化的操作，从线程角度看，在当前线程修改共享资源期间，其他线程不可访问该资源，

原子操作对于多线程并发模型来说，不会发生有别于单线程的意外情况，共享资源的完整性可以得到保证。

一般情况下，原子操作是通过互斥访问来保证的，通常由特殊的 CPU 指令提供保护，可以借助于 `sync.Mutex` 来粗粒度模拟实现，

对于多线程模型程序而言，进入临界区前后进行枷锁和解锁都是必须的，用于保证竞争资源的正确性，

但是如果用互斥锁来保护一个数值型的共享资源，麻烦并且效率低下，标准库的 `sync/atomic` 包对原子操作提供支持：

```go
import (
    "sync"
    "sync/atomic"
)

var total uint64

func worker(wg *sync.WaitGroup) {
    defer wg.Done()

    var i uint64
    for i = 0; i <= 100; i++ {
        atomic.AddUint64(&total, i)
    }
}

func main() {
    var wg sync.WaitGroup
    wg.Add(2)

    go worker(&wg)
    go worker(&wg)
    wg.Wait()
}
```

互斥锁的代价比普通整数的原子读写高很多，在性能敏感的地方可以增加一个数字型的标志位，

通过原子检测标志位状态降低互斥锁的使用次数来提高性能，原子操作配合互斥锁可以实现非常高效的单例模式：

```go
type singleton struct {}

var (
    instance    *singleton
    initialized uint32
    mu          sync.Mutex
)

func Instance() *singleton {
    if atomic.LoadUint32(&initialized) == 1 {
        return instance
    }

    mu.Lock()
    defer mu.Unlock()

    if instance == nil {
        defer atomic.StoreUint32(&initialized, 1)
        instance = &singleton{}
    }
    return instance
}
```

可以将通用的代码提取出来，就成了标准库中 `sync.Once` 的实现：

```go
type Once struct {
    m    Mutex
    done uint32
}

func (o *Once) Do(f func()) {
    if atomic.LoadUint32(&o.done) == 1 {
        return
    }

    o.m.Lock()
    defer o.m.Unlock()

    if o.done == 0 {
        defer atomic.StoreUint32(&o.done, 1)
        f()
    }
}
```

<strong>基于 `sync.Once` 重新实现单件模式：</strong>

```go
var (
    instance *singleton
    once     sync.Once
)

func Instance() *singleton {
    once.Do(func() {
        instance = &singleton{}
    })
    return instance
}
```

`atomic.Value` 原子对象提供了 `Load` 和 `Store` 两个原子方法，分别用于加载和保存数据，

返回值和参数都是 `interface{}` 类型，因此可以用于任意的自定义复杂类型：

```go
var config atomic.Value // 保存当前配置信息

// 初始化配置信息
config.Store(loadConfig())

// 启动一个后台线程, 加载更新后的配置信息
go func() {
    for {
        time.Sleep(time.Second)
        config.Store(loadConfig())
    }
}()

// 用于处理请求的工作者线程始终采用最新的配置信息
for i := 0; i < 10; i++ {
    go func() {
        for r := range requests() {
            c := config.Load()
            // ...
        }
    }()
}
```

简化的生产者消费者模型，后台线程生成最新的配置信息，前台多个工作者获取最新信息，所有线程共享配置资源。

## 顺序一致性内存模型

在 Go 语言中，同一个 Goroutine 线程内部，顺序一致性内存模型是得到保证的，但是不同的协程之间，无法保证，

需要通过明确定义的同步时间来作为同步的参考，如果两个事件不可排序，那么就说这两个事件是并发的，

<strong>为了最大化并行，Go 语言编译器和处理器在不影响上述规定的前提下可能会对执行语句进行重新排序。</strong>

解决问题的办法就是通过同步原语来给两个事件明确排序：

````go
func main() {
    done := make(chan int)

    go func(){
        println("你好, 世界")
        done <- 1
    }()

    <-done
}
````

也可以通过 `sync.Mutex` 互斥量来实现同步：

```go
func main() {
    var mu sync.Mutex

    mu.Lock()
    go func(){
        println("你好, 世界")
        mu.Unlock()
    }()

    // 等待锁释放，因此会阻塞程序
    mu.Lock()
}
```

## 不靠谱的同步

刚接触 Go 语言的话，可能希望通过加入一个随机的休眠时间来保证正常的输出：

```go
func main() {
    go println("hello, world")
    time.Sleep(time.Second)
}
```

这个程序是不稳健的，依然有失败的可能性，严谨的并发程序的正确性不应该是依赖于 CPU 的执行速度和休眠时间等不靠谱的因素的，

根据线程内顺序一致性，结合 `channel` 或 `sync` 同步事件的可排序性来推导，最终完成各个线程各段代码的偏序关系排序，

如果两个事件无法根据规则排序，那么就是并发的，也就是执行先后顺序不可靠的，解决同步问题的思路是相同的：使用显式的同步。

