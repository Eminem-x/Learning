# 分布式搜索引擎

数据库系统本身要保证实时和强一致性，所以其功能设计上都是为了满足一致性需求，关系型数据库一般用于实现 OLTP 系统：

>在线交易处理（OLTP, Online transaction processing）是指透过信息系统、电脑网络及数据库，
>
>以线上交易的方式处理一般即时性的作业数据，和更早期传统数据库系统大量批量的作业方式并不相同。
>
>OLTP 通常被运用于自动化的数据处理工作，如订单输入、金融业务… 等反复性的日常性交易活动。
>
>和其相对的是属于决策分析层次的联机分析处理（OLAP）。

在互联网的业务场景中，也有一些实时性要求不高 (可以接受多秒的延迟)，但是查询复杂性却很高的场景，比如电商订单，

每天有千万级别的订单，那么在这个数据库中查询和建立合适的索引都是一件非常难的事情。

在 CRM 或客服类系统中，常常有根据关键字进行搜索的需求，并且每天会有数以万计用户的信息记录，

考虑到事件溯源，记录至少要存 2~3 年，又是千万级甚至上亿的数据，根据关键字进行一次 like 查询，可能整个 MySQL 就直接挂掉了。

这时候就需要<strong>搜索引擎</strong>来救场了。

## 搜索引擎

Elasticsearch 是开源分布式搜索引擎，其依赖于 Lucene 实现，在部署和运维方面做了很多优化。

#### 倒排索引

虽然 es 是针对搜索场景来定制的，但如前文所言，实际应用中常常用 es 来作为 database 来使用，

就是因为倒排列表的特性，可以用比较朴素的观点来理解倒排索引：

<img src="https://raw.githubusercontent.com/Eminem-x/Learning/main/Go/Go%E8%AF%AD%E8%A8%80%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B/pic/%E5%80%92%E6%8E%92%E5%88%97%E8%A1%A8.png" style="max-width: 80%">

elasticsearch 中的数据进行查询时，本质就是求多个排好序的序列求交集,

非数值类型字段涉及到分词问题，大多数内部使用场景下，可以直接使用默认的 bi-gram 分词：

即将所有 `Ti` 和 `T(i+1)` 组成一个词（在 Elasticsearch 中叫 term），然后再编排其倒排列表，倒排列表大概就是这样的：

<img src="https://raw.githubusercontent.com/Eminem-x/Learning/main/Go/Go%E8%AF%AD%E8%A8%80%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B/pic/%E5%80%92%E6%8E%92%E7%A4%BA%E4%BE%8B.png" style="max-width: 70%">

当用户搜索'天气很好'时，其实就是求：天气、气很、很好三组倒排列表的交集，但这里的相等判断逻辑有些特殊，用伪代码表示一下：

```go
func equal() {
    if postEntry.docID of '天气' == postEntry.docID of '气很' &&
        postEntry.offset + 1 of '天气' == postEntry.offset of '气很' {
            return true
    }

    if postEntry.docID of '气很' == postEntry.docID of '很好' &&
        postEntry.offset + 1 of '气很' == postEntry.offset of '很好' {
        return true
    }

    if postEntry.docID of '天气' == postEntry.docID of '很好' &&
        postEntry.offset + 2 of '天气' == postEntry.offset of '很好' {
        return true
    }

    return false
}
```

多个有序列表求交集的时间复杂度是：`O(N*M)`，N 为给定列表当中元素数最小的集合，M 为给定列表的个数。

在整个算法中起决定作用的是最短的倒排列表的长度，其次是词数总和，一般词数不会很大（搜索引擎里一般不会输入几百字），

所以起决定性作用的，一般是所有倒排列表中，最短的那一个的长度，

因此，文档总数很多的情况下，搜索词的倒排列表最短的那一个不长时，搜索速度也是很快的，

如果用关系型数据库，那就需要按照索引（如果有的话）来慢慢扫描了。

#### 查询 DSL

> domain-specific langugge：在特定领域下的上下文语言

es 定义了一套查询 DSL，当我们把 es 当数据库使用时，需要用到其 bool 查询。

es 的 `Bool Query` 方案，就是用 json 来表达了这种程序语言中的 Boolean Expression，为什么可以这么做呢？

因为 json 本身是可以表达树形结构的，程序代码在被编译器 parse 之后，也会变成 AST，

而 AST 抽象语法树，顾名思义，就是树形结构。理论上 json 能够完备地表达一段程序代码被 parse 之后的结果，

这里的 Boolean Expression 被编译器 Parse 之后也会生成差不多的树形结构，而且只是整个编译器实现的一个很小的子集。

#### 将 sql 转换为 DSL

比如我们有一段 bool 表达式，

`user_id = 1 and (product_id = 1 and (star_num = 4 or star_num = 5) and banned = 1)`，

写成 SQL 是如下形式：

```sql
select * from xxx where user_id = 1 and (
    product_id = 1 and (star_num = 4 or star_num = 5) and banned = 1
)
```

写成 es 的 DSL 是如下形式：

```json
{
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "user_id": {
              "query": "1",
              "type": "phrase"
            }
          }
        },
        {
          "match": {
            "product_id": {
              "query": "1",
              "type": "phrase"
            }
          }
        },
        {
          "bool": {
            "should": [
              {
                "match": {
                  "star_num": {
                    "query": "4",
                    "type": "phrase"
                  }
                }
              },
              {
                "match": {
                  "star_num": {
                    "query": "5",
                    "type": "phrase"
                  }
                }
              }
            ]
          }
        },
        {
          "match": {
            "banned": {
              "query": "1",
              "type": "phrase"
            }
          }
        }
      ]
    }
  },
  "from": 0,
  "size": 1
}
```

es 的 DSL 虽然很好理解，但是手写起来非常费劲，但是 SQL 解析后的结构与 DSL 结构差不多：

<img src="https://raw.githubusercontent.com/Eminem-x/Learning/main/Go/Go%E8%AF%AD%E8%A8%80%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B/pic/sql%E8%A7%A3%E6%9E%90.png" style="max-width: 70%">

结构上一致，逻辑上就可以相互转换，以广度优先对 AST 树进行遍历，然后将二元表达式转换成 json 字符串，再拼装起来就可以了。

可以参考：`github.com/cch123/elasticsql`

## 异构数据同步

在实际应用中，很少直接向搜索引擎中写入数据，更为常见的是将 MySQL 或其他关系型数据库中的数据同步过来，

而搜索引擎的使用方只能对数据进行查询，无法进行修改和删除。

#### 通过时间戳进行增量数据同步

<img src="https://raw.githubusercontent.com/Eminem-x/Learning/main/Go/Go%E8%AF%AD%E8%A8%80%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B/pic/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5.png" style="max-width: 70%">

这种同步方式与业务强绑定，例如出库单，并不需要非常实时，稍微有延迟也可以接受，那么可以从 MySQL 的出库表单中，

把最近十分钟创建的所有出库单取出，存入 es 中，逻辑可以表达为下面的 SQL：

`select * from wms_orders where update_time >= date_sub(now(), interval 10 minute);`

考虑到边界情况，可以让这个时间段的数据与前一次的有一些重叠：

```go
select * from wms_orders where update_time >= date_sub(
    now(), interval 11 minute
);
```

这种方案的缺点显而易见，必须要求业务数据严格遵守一定的规范。比如这里的，必须要有 update_time 字段

并且每次创建和更新都要保证该字段有正确的时间值，否则同步逻辑就会丢失数据。

#### 通过 binlog 进行数据同步

<img src="https://raw.githubusercontent.com/Eminem-x/Learning/main/Go/Go%E8%AF%AD%E8%A8%80%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B/pic/binlog%E5%90%8C%E6%AD%A5.png" style="max-width: 70%">

业界使用较多的是阿里开源的 Canal，来进行 binlog 解析与同步。

canal 会伪装成 MySQL 的从库，然后解析好行格式的 binlog，再以更容易解析的格式（例如 json）发送到消息队列。

由下游的 Kafka 消费者负责把上游数据表的自增主键作为 es 的文档的 id 进行写入，这样可以保证每次接收到 binlog 时，

对应 id 的数据都被覆盖更新为最新，MySQL 的 Row 格式的 binlog 会将每条记录的所有字段都提供给下游，

所以在向异构数据目标同步数据时，不需要考虑数据是插入还是更新，只要一律按 id 进行覆盖即可。

这种模式同样需要业务遵守一条数据表规范，即表中必须有唯一主键 id 来保证我们进入 es 的数据不会发生重复。

一旦不遵守该规范，那么就会在同步时导致数据重复。当然，可以为每一张表定制消费者的逻辑，这就不是通用系统讨论的范畴了。